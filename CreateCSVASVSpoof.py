import os
from pathlib import Path

import pandas as pd
import numpy as np
import torchaudio
import torch
from pydub import AudioSegment
from torch.utils.data import DataLoader
from DeepLearningModel import AudioConfig, AudioProcessor, DeepfakeDataset, DeepfakeClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report


class ASVSpoofProcessor(AudioProcessor):

    def __init__(self, config):
        super(ASVSpoofProcessor, self).__init__(config)

    def extract_features(self, waveform: torch.Tensor, target_sample_rate=16000, target_duration=5):
        current_num_samples = waveform.shape[0]
        target_num_samples = int(target_duration * target_sample_rate)
        if current_num_samples == target_num_samples:
            # GiÃ  della lunghezza corretta
            processed_waveform = waveform
        elif current_num_samples > target_num_samples:
            # Audio piÃ¹ lungo: applica il ritaglio centrale (center cropping)
            start_sample = (current_num_samples - target_num_samples) // 2
            processed_waveform = waveform[:, start_sample: start_sample + target_num_samples]
            # print(f"Audio {audio_path} ritagliato da {current_num_samples} a {target_num_samples} campioni.")
        else:  # current_num_samples < target_num_samples
            # Audio piÃ¹ corto: applica il padding con silenzio alla fine
            padding_needed = target_num_samples - current_num_samples
            # (pad_left, pad_right)
            processed_waveform = torch.nn.functional.pad(waveform, (0, padding_needed))
            # print(f"Audio {audio_path} riempito da {current_num_samples} a {target_num_samples} campioni.")
        return super(ASVSpoofProcessor, self).extract_features(processed_waveform)



# ----------------------------------------------------------------------------
# 3. FUNZIONE PER CALCOLARE L'EQUAL ERROR RATE (EER)
# ----------------------------------------------------------------------------
def calculate_eer(y_true, y_scores_positive_class):
    """
    Calcola l'Equal Error Rate (EER).
    y_true: Etichette binarie vere (0 o 1).
    y_scores_positive_class: Score del modello per la classe positiva (es. 'spoof').
    """
    fpr, tpr, thresholds = roc_curve(y_true, y_scores_positive_class, pos_label=1)  # Assumiamo 1 = spoof
    fnr = 1 - tpr
    eer_index = np.nanargmin(np.abs(fnr - fpr))
    eer_value = (fpr[eer_index] + fnr[eer_index]) / 2
    return eer_value * 100  # Riportato come percentuale


# ----------------------------------------------------------------------------
# 4. FUNZIONE PRINCIPALE DI TEST (MODIFICATA PER CHIAREZZA)
# ----------------------------------------------------------------------------
def testOnASVspoof(model,  # Il tuo modello PyTorch pre-caricato
                   asv_csv_path,  # Percorso al file CSV (es. 'tuo_dataset.csv')
                   audio_root_dir,  # Directory radice dei file audio (es. '/path/to/ASVspoof2021_DF_eval/flac/')
                   audioProcessor,  # La TUA funzione di estrazione feature
                   batch_size=64,
                   label_mapping=None,  # Dizionario opzionale es. {'bonafide': 0, 'spoof': 1}
                   # Se None, usa il default {'bonafide': 0, 'spoof': 1}
                   file_extension=".flac"):
    """
    Valuta un modello PyTorch su un sottoinsieme di ASVspoof.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"â„¹ï¸ Dispositivo utilizzato: {device}")

    model.to(device)
    model.eval()  # Imposta il modello in modalitÃ  valutazione

    current_label_mapping = label_mapping if label_mapping is not None else {'bonafide': 0, 'spoof': 1}
    print(f"â„¹ï¸ Utilizzo del mapping etichette: {current_label_mapping}")

    # Nomi per il classification report (se il mapping Ã¨ {0: 'bonafide', 1: 'spoof'} invertito)
    try:
        # Inverti il mapping per ottenere nomi leggibili dalle etichette numeriche
        idx_to_label_name = {v: k for k, v in current_label_mapping.items()}
        report_target_names = [idx_to_label_name[i] for i in sorted(idx_to_label_name.keys())]
    except Exception:
        report_target_names = None  # Fallback

    # Crea Dataset e DataLoader
    eval_dataset = DeepfakeDataset(
        root_dir=audio_root_dir,
        metadata_df=asv_csv_path,
        processor=audioProcessor,
        augment=False
    )

    if len(eval_dataset) == 0:
        print("âš ï¸ Il dataset di valutazione Ã¨ vuoto! Controlla i percorsi e il CSV.")
        return None

    eval_dataloader = DataLoader(
        eval_dataset,
        batch_size=batch_size,
        shuffle=False,  # Non serve mischiare per la valutazione
    )
    all_true_labels = []
    all_predicted_classes = []
    all_positive_class_scores = []  # Score per la classe 'spoof' (per EER/AUC)

    print(f"â–¶ï¸ Inizio valutazione su {len(eval_dataset)} campioni...")
    with torch.no_grad():  # Disabilita il calcolo dei gradienti
        for i, (batch_features, batch_true_labels) in enumerate(eval_dataloader):

            model_outputs = model(batch_features['mel'].to(device))  # Output raw del modello (logits)

            # --- Elabora l'output del modello ---
            # Questo dipende da come Ã¨ fatto l'ultimo layer del tuo modello
            # e dalla loss function usata in addestramento.

            # Scenario 1: Output logits per 2 classi (es. [logit_bonafide, logit_spoof])
            if model_outputs.ndim > 1 and model_outputs.shape[1] == 2:
                probabilities = torch.softmax(model_outputs, dim=1)
                # Assumiamo che la classe 'spoof' sia all'indice 1
                scores_for_spoof_class = probabilities[:, current_label_mapping.get('spoof', 1)]
                _, predicted_batch_classes = torch.max(probabilities, dim=1)
            # Scenario 2: Output singolo logit per campione (es. per BCEWithLogitsLoss)
            # dove un logit positivo indica 'spoof'
            elif model_outputs.ndim == 1 or (model_outputs.ndim == 2 and model_outputs.shape[1] == 1):
                model_outputs = model_outputs.squeeze()  # Assicura sia 1D
                scores_for_spoof_class = torch.sigmoid(model_outputs)  # ProbabilitÃ 
                predicted_batch_classes = (scores_for_spoof_class > 0.5).long()
            else:
                raise ValueError(
                    f"Forma dell'output del modello ({model_outputs.shape}) non gestita. "
                    "Adatta la sezione di elaborazione dell'output."
                )

            all_true_labels.extend(batch_true_labels.cpu().numpy())
            all_predicted_classes.extend(predicted_batch_classes.cpu().numpy())
            all_positive_class_scores.extend(scores_for_spoof_class.cpu().numpy())

            if (i + 1) % (max(1, len(eval_dataloader) // 10)) == 0:  # Stampa progresso circa 10 volte
                print(f"  Elaborato batch {i + 1}/{len(eval_dataloader)}")

    print("âœ… Valutazione completata. Calcolo metriche...")

    # Converti liste in array NumPy
    y_true_np = np.array(all_true_labels)
    y_pred_classes_np = np.array(all_predicted_classes)
    y_scores_spoof_np = np.array(all_positive_class_scores)

    # Calcola Metriche
    accuracy = accuracy_score(y_true_np, y_pred_classes_np)

    if len(np.unique(y_true_np)) < 2:  # Controlla se c'Ã¨ almeno una istanza per ogni classe
        print("âš ï¸ Trovata solo una classe nelle etichette vere. AUC e EER potrebbero essere non definiti o fuorvianti.")
        auc = float('nan')
        eer = float('nan')
    else:
        try:
            auc = roc_auc_score(y_true_np, y_scores_spoof_np)
        except ValueError as e:
            print(f"Errore nel calcolo AUC: {e}")
            auc = float('nan')
        try:
            # Assicurati che y_true_np contenga 0 per 'bonafide' e 1 per 'spoof' per EER
            eer = calculate_eer(y_true_np, y_scores_spoof_np)
        except Exception as e:
            print(f"Errore nel calcolo EER: {e}")
            eer = float('nan')

    print("\n--- Risultati della Valutazione ---")
    print(f"ðŸŽ¯ Accuratezza: {accuracy:.4f}")
    print(f"ðŸ“ˆ AUC: {auc:.4f}")
    print(f"ðŸ“Š EER: {eer:.2f}%")  # EER Ã¨ spesso riportato come percentuale

    print("\nðŸ“‹ Classification Report:")
    print(classification_report(y_true_np, y_pred_classes_np, target_names=report_target_names, digits=4))

    results = {"accuracy": accuracy, "auc": auc, "eer": eer}
    return results


def CreateCSVASVSpoof(pathKey):
    data = []

    with open(pathKey,'r') as csvfile:
        for line in csvfile.readlines():
            df = {}
            split_line = line.split(' ')
            name_audio = split_line[1]
            label_audio = split_line[5]
            df.update({'file': name_audio+".wav", 'label': label_audio})
            data.append(df)
    return pd.DataFrame(data)


def convert_flac_to_wav_inplace(input_dir: Path):
    input_dir = Path(input_dir)

    for flac_file in input_dir.rglob("*.flac"):
        try:
            print(f"Converting: {flac_file}")
            audio = AudioSegment.from_file(flac_file, format="flac")

            wav_path = flac_file.with_suffix('.wav')
            audio.export(wav_path, format="wav")

            flac_file.unlink()  # rimuove il file .flac originale
            print(f"âœ“ Converted and replaced: {flac_file.name}")
        except Exception as e:
            print(f"âœ— Failed to convert {flac_file}: {e}")

if __name__ == '__main__':
    eval_path = Path('B:/4835108/ASVspoof2021_DF_eval_part00/ASVspoof2021_DF_eval/flac')
    pathKey = './trial_metadata.txt'

    #convert_flac_to_wav_inplace(eval_path)

    df = CreateCSVASVSpoof(pathKey)
    df.to_csv("ASVSpoofData.csv", index=False, columns=['file', 'label'])
    modelPath = 'best_hardened_detector.pth'
    modelArchitecture = DeepfakeClassifier()
    # Caricamento forzato, solo se ti fidi della fonte del file
    state_dict = torch.load(modelPath, map_location=torch.device('cuda'), weights_only=False)
    modelArchitecture.load_state_dict(state_dict['model_state_dict'])
    modelArchitecture.to(device="cuda")
    config = AudioConfig()
    processor = ASVSpoofProcessor(config)
    testOnASVspoof(
        model=modelArchitecture,
        asv_csv_path=df[:152956],
        audio_root_dir=eval_path,
        audioProcessor=processor
    )









